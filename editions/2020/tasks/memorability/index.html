<!DOCTYPE html>

<html lang="en">
  <head>
  <meta charset="UTF-8">
  <link rel="shortcut icon" href="/assets/img/mediaeval-favicon.png" type="image/png">
  <!--Import Google Icon Font-->
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
  <!--Import materialize.css-->
  <link type="text/css" rel="stylesheet" href="/assets/css/materialize.min.css"  media="screen,projection"/>
  <link type="text/css" rel="stylesheet" href="/assets/css/main.css"  media="screen,projection"/>
  <!-- Add icon library -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <!--Let browser know website is optimized for mobile-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  

  <!-- seo tags -->
  <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Predicting Media Memorability | MediaEval Benchmark</title>
<meta name="generator" content="Jekyll v3.8.7" />
<meta property="og:title" content="Predicting Media Memorability" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="MediaEval Benchmarking Initiative Multimedia Evaluation" />
<meta property="og:description" content="MediaEval Benchmarking Initiative Multimedia Evaluation" />
<link rel="canonical" href="/editions/2020/tasks/memorability/" />
<meta property="og:url" content="/editions/2020/tasks/memorability/" />
<meta property="og:site_name" content="MediaEval Benchmark" />
<meta property="og:image" content="/assets/img/mediaeval-white.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-07-06T15:20:41+00:00" />
<script type="application/ld+json">
{"description":"MediaEval Benchmarking Initiative Multimedia Evaluation","image":"/assets/img/mediaeval-white.png","@type":"BlogPosting","headline":"Predicting Media Memorability","dateModified":"2020-07-06T15:20:41+00:00","datePublished":"2020-07-06T15:20:41+00:00","mainEntityOfPage":{"@type":"WebPage","@id":"/editions/2020/tasks/memorability/"},"url":"/editions/2020/tasks/memorability/","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

  <!-- Manual seo tags -->

</head>

  <body>

    <div>
    


<div class="navbar-fixed">
  <nav>
    <div class="nav-wrapper green darken-4">
      <a href="/" class="brand-logo" style="padding-left: 20px">
        <h3 class="northumbria" style="margin-top: 20px;color:white;">Mediaeval</h3>
      </a>
      <!-- Small screen definition -->
      <a href="#" data-target="mobile-nav" class="sidenav-trigger">
        <i class="material-icons" style="color:white;">menu</i>
      </a>
      <!-- Big screen Structure -->
      <ul class="materialize right hide-on-med-and-down">
        <li><a href="/"><i class="material-icons" style="color:white;">home</i></a></li>
        
          <li><a href="/editions/2020/" style="color:white;">MediaEval 2020</a></li>
        
        
          
            
              <li><a class="dropdown-trigger" data-target="editions" style="color:white;">
                MediaEval History<i class="material-icons right">arrow_drop_down</i>
              </a></li>
            
          
        
          
            
              <li><a href="/about/" style="color:white;">About MediaEval</a></li>
            
          
        
          
            
              <li><a href="/bib/" style="color:white;">Bibliography</a></li>
            
          
        
          
        
          
        
          
        
      </ul>
    </div>
  </nav>
</div>

<!-- Big screen dropdown Structure -->
<ul class="dropdown-content materialize" id="editions">
  
  <li><a href="http://www.multimediaeval.org/" target="_blank">pre-2020</a></li>
</ul>

<!-- Mobile Structure -->
<ul class="materialize sidenav green darken-4" id="mobile-nav">
  <li><a href="/" style="color:white;">Home</a></li>
  
  <li><a href="/editions/2020/" style="color:white;">MediaEval 2020</a></li>
  
  
    
      
  <li><a class="dropdown-trigger" data-target="mobile-editions" style="color:white;">
    MediaEval History<i class="material-icons right" style="color:white;">arrow_drop_down</i>
  </a></li>
      
    
  
    
      
  <li><a href="/about/" style="color:white;">About MediaEval</a></li>
      
    
  
    
      
  <li><a href="/bib/" style="color:white;">Bibliography</a></li>
      
    
  
    
  
    
  
    
  
</ul>

<!-- Mobile dropdown Structure -->
<ul class="dropdown-content materialize" id="mobile-editions">
  
  <li><a href="http://www.multimediaeval.org/" target="_blank">pre-2020</a></li>
</ul>

</div>

    

    <div class="container">
      <div class="row">
          <header id="main" style="background-image: url('')">
    <h2>Predicting Media Memorability</h2>
  </header>

  <!-- # please respect the structure below-->

<h4 id="task-description">Task Description</h4>

<h4 id="target-group">Target Group</h4>

<h4 id="data">Data</h4>

<h4 id="evaluation-methodology">Evaluation Methodology</h4>

<h4 id="references-and-recommended-reading">References and recommended reading</h4>
<!-- # Please use the ACM format for references https://www.acm.org/publications/authors/reference-formatting (but no DOI needed)-->
<!-- # The paper title should be a hyperlink leading to the paper online-->

<h4 id="task-organizers">Task organizers</h4>

<ul>
  <li>Alba García Seco de Herrera, University of Essex, UK</li>
  <li>Rukiye Savran Kiziltepe, University of Essex, UK</li>
  <li>Faiyaz Doctor, University of Essex, UK</li>
  <li>Mihai Gabriel Constantin, University Politehnica of Bucharest, Romania</li>
  <li>Bogdan Ionescu, University Politehnica of Bucharest, Romania</li>
  <li>Alan Smeaton, Graham Healy, Dublin City University, Ireland</li>
  <li>Claire-Hélène Demarty, InterDigital, R&amp;I, France</li>
</ul>

<h4 id="task-auxiliaries">Task auxiliaries</h4>

<ul>
  <li>Jon Chamberlain, University of Essex, UK</li>
</ul>

<h4 id="task-schedule">Task Schedule</h4>
<ul>
  <li>XX July: Data release <!-- # Replace XX with your date. Latest possible is 31 July--></li>
  <li>XX October: Runs due <!-- # Replace XX with your date. Latest possible is 31 October--></li>
  <li>15 November: Results returned  <!-- Fixed. Please do not change--></li>
  <li>30 November: Working notes paper  <!-- Fixed. Please do not change--></li>
  <li>Early December: MediaEval 2020 Workshop <!-- Fixed. Please do not change--></li>
</ul>

<p>Workshop will be held online. Exact dates to be announced.
<!-- # Pleaes integrate the information below into the structure above, and then delete everything below this line. Thanks.--></p>

<h3 id="task-description-1">Task Description</h3>

<h4 id="introduction">Introduction</h4>

<p>Media platforms such as social networks, media advertisement, information retrieval and recommendation systems deal with exponentially growing data day after day. Enhancing the relevance of multimedia occurrences in our everyday life requires new ways to organize – in particular, to retrieve – digital content. Like other metrics of video importance, such as aesthetics or interestingness, memorability can be regarded as useful to help make a choice between competing videos. This is even truer when one considers the specific use cases of creating commercials or creating educational content. Because the impact of different multimedia content, images or videos, on human memory is unequal, the capability of predicting the memorability level of a given piece of content is obviously of high importance for professionals in the field of advertising. Beyond advertising, other applications, such as filmmaking, education, content retrieval, etc., may also be impacted by the proposed task.</p>

<p>The task requires participants to automatically predict memorability scores for videos, that reflect the probability for a video to be remembered. Participants will be provided with an extensive data set of videos with memorability annotations, related information, and pre-extracted state-of-the-art visual features.</p>

<h4 id="new-for-2020">New for 2020</h4>
<p>In this 3rd edition of the task, a more robust collection of videos is provided, which is retrieved from the TREC Video Retrieval Evaluation (TRECVID) task. Optionally, we may use descriptive captions from their use in the TRECVid automatic video captioning task.</p>

<h4 id="target-group-1">Target group</h4>
<p>Researchers will find this task interesting if they work in the areas of human perception and scene understanding, such as image and video interestingness, memorability, attractiveness, aesthetics prediction, event detection, multimedia affect and perceptual analysis, multimedia content analysis, machine learning (though not limited to).</p>

<h4 id="data-1">Data</h4>
<p>Data is composed of 6,000 short videos retrieved from TRECVid. Each video consists of a coherent unit in terms of meaning and is associated with two scores of memorability that refer to its probability to be remembered after two different durations of memory retention. Similar to previous editions of the task [6], memorability has been measured using recognition tests, i.e., through an objective measure, a few minutes after the memorization of the videos (short term), and then 24 to 72 hours later (long term). The videos are shared under Creative Commons licenses that allow their redistribution. They come with a set of pre-extracted features, such as: Aesthetic Features, C3D, Captions, Colour Histograms, HMP, HoG, Fc7 layer from InceptionV3, LBP, or ORP.  In comparison to the videos used in this task in 2018 and 2019, the TRECVid videos have much more action happening in them and thus are more interesting for subjects to view.</p>

<h4 id="ground-truth">Ground Truth</h4>
<p>The ground truth for memorability will be collected through recognition tests, and thus results from objective measures of memory performance.</p>

<h4 id="evaluation-methodology-1">Evaluation Methodology</h4>
<p>The outputs of the prediction models – i.e., the predicted memorability scores for the videos – will be compared with ground truth memorability scores using classic evaluation metrics (e.g., Spearman’s rank correlation).</p>

<h4 id="references-and-recommended-reading-1">References and recommended reading</h4>
<p>[1] Aditya Khosla, Akhil S Raju, Antonio Torralba, and Aude Oliva. 2015. Understanding and predicting image memorability at a large scale. In Proc. IEEE Int. Conf. on Computer Vision (ICCV). 2390–2398.<br />
[2] Phillip Isola, Jianxiong Xiao, Devi Parikh, Antonio Torralba, and Aude Oliva. 2014. What makes a photograph memorable? IEEE Transactions on Pattern Analysis and Machine Intelligence 36, 7 (2014), 1469–1482.<br />
[3] Hammad Squalli-Houssaini, Ngoc Duong, Gwenaëlle Marquant, and Claire-Hélène Demarty. 2018. Deep learning for predicting image memorability. In Proc. IEEE Int. Conf. on Audio, Speech and Language Processing (ICASSP).<br />
[4] Junwei Han, Changyuan Chen, Ling Shao, Xintao Hu, Jungong Han, and Tianming Liu. 2015. Learning computational models of video memorability from fMRI brain imaging. IEEE transactions on cybernetics 45, 8 (2015), 1692–1703.<br />
[5] Sumit Shekhar, Dhruv Singal, Harvineet Singh, Manav Kedia, and Akhil Shetty. 2017. Show and Recall: Learning What Makes Videos Memorable. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2730–2739.<br />
[6] Romain Cohendet, Claire-Hélène Demarty, Ngoc Duong, and Martin Engilberge. “VideoMem: Constructing, Analyzing, Predicting Short-term and Long-term Video Memorability.” Proceedings of the IEEE International Conference on Computer Vision. 2019.<br />
[7] M.G. Constantin, M. Redi, G. Zen, B. Ionescu, “Computational Understanding of Visual Interestingness Beyond Semantics: Literature Survey and Analysis of Covariates”, ACM Computing Surveys, 52(2), 2019.</p>

<h3 id="big-picture-of-the-task">Big Picture of the Task</h3>

<h4 id="innovation">Innovation</h4>
<p>The computational understanding of video memorability (VM) follows on from the study of image memorability prediction which has attracted increasing attention since the seminal work of Isola et al. [2]. Models achieved very good results at predicting image memorability [1, 3]. In contrast, research on VM from a computer science point of view is in its early stage. The scarcity of studies on VM can be explained by several reasons. Firstly, there is no publicly available data set to train and test models. The second point, closely related to the previous one, is the lack of a common definition for VM. Regarding modelling, the previous attempts at predicting VM [5, 6] highlighted several features which contribute to the prediction of VM, such as semantic, saliency and color features, but the work is far from complete and our capacity to propose efficient computational models will help to meet the challenge of VM prediction. The goal of this task is to participate in the harmonization and the advancement of this emerging search field. Furthermore, in contrast to previous work on image memorability prediction, where memorability was measured a few minutes after memorization, we propose a dataset with “long-term” memorability annotations. We expect the predictions of the models trained on this data to be more representative of long-term memory, which is used preferably in numerous applications.</p>

<h4 id="focus">Focus</h4>
<p>Understanding what makes a video memorable has a very broad range of current applications, e.g., education and learning, content retrieval and search, content summarization, storytelling, targeted advertising, content recommendation and filtering. Efficient memorability prediction models will also push forward the semantic understanding of multimedia content, by putting human cognition and perception in the center of the scene understanding.</p>

<h4 id="risk-management">Risk management</h4>
<p>The task has been successfully organised in 2018 and 2019. The experience gained will help us to anticipate and overcome the inherent difficulties in organizing such a task.</p>

<h4 id="task-organization-team">Task organization team</h4>

<p>The task benefits from a team from three different research sites and countries, and from different research fields, that have complementary expertise. Most of the organizers already have experience in organizing tasks in the context of the MediaEval and ImageCLEF, and are experts in their fields. University of Essex and University Politehnica of Bucharest are in charge of the creation of the video-based subtask collection. Otherwise, the different teams – University of Essex, University Politehnica of Bucharest and InterDigital – will be involved and will interact in all the aspects of the task (management, dissemination, etc.).</p>

<h4 id="task-schedule-1">Task Schedule</h4>
<p>Data release: <br />
Run submission: <br />
Results returned: <br />
Working Notes paper deadline:</p>


      </div>
    </div>

    
<footer class='page-footer green darken-4'>
  <div class='container'>

    <div class='row'>
      <div class="col l6 s12">
        <h5 class="white-text">What is MediaEval?</h5>
        <p>MediaEval is a benchmarking initiative dedicated to evaluating new algorithms for multimedia access and retrieval. 
          It emphasizes the ‘multi’ in multimedia and focuses on human and social aspects of multimedia tasks.</p>

        <p>For more information contact Martha Larson m.larson (at) cs.ru.nl</p>
      </div>
      <div class="col l4 offset-l2 s12">
        <h5 class="white-text">Links</h5>
        <a href='https://twitter.com/multimediaeval' target="_blank">
          <i class="fa fa-twitter fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
        <a href='https://github.com/multimediaeval' target="_blank">
          <i class="fa fa-github fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
        <a href='https://www.flickr.com/photos/69524595@N06/' target="_blank">
          <i class="fa fa-flickr fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
        <a href='https://www.youtube.com/channel/UCc-1NW1Uo2o_zI4F81iyTcw' target="_blank">
          <i class="fa fa-youtube fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
      </div>
    </div>

  </div>
    <div class="footer-copyright">
      <div class="container grey-text text-lighten-4">
      &copy; 2020 MediaEval Multimedia Benchmark
    </div>
  </div>
</footer>


    <!--JavaScript at end of body for optimized loading-->
    <script type="text/javascript" src="/assets/js/materialize.min.js"></script>
    <script type="text/javascript" src="/assets/js/main.js"></script>
  </body>

</html>
