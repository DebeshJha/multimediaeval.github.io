<!DOCTYPE html>

<html lang="en">
  <head>
  <meta charset="UTF-8">
  <link rel="shortcut icon" href="/assets/img/mediaeval-favicon.png" type="image/png">
  <!--Import Google Icon Font-->
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
  <!--Import materialize.css-->
  <link type="text/css" rel="stylesheet" href="/assets/css/materialize.min.css"  media="screen,projection"/>
  <link type="text/css" rel="stylesheet" href="/assets/css/main.css"  media="screen,projection"/>
  <!-- Add icon library -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <!--Let browser know website is optimized for mobile-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  

  <!-- seo tags -->
  <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Insight for Wellbeing | MediaEval Benchmark</title>
<meta name="generator" content="Jekyll v3.8.7" />
<meta property="og:title" content="Insight for Wellbeing" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="MediaEval Benchmarking Initiative Multimedia Evaluation" />
<meta property="og:description" content="MediaEval Benchmarking Initiative Multimedia Evaluation" />
<link rel="canonical" href="/editions/2020/tasks/lifelogging/" />
<meta property="og:url" content="/editions/2020/tasks/lifelogging/" />
<meta property="og:site_name" content="MediaEval Benchmark" />
<meta property="og:image" content="/assets/img/mediaeval-white.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-07-09T21:03:05+00:00" />
<script type="application/ld+json">
{"description":"MediaEval Benchmarking Initiative Multimedia Evaluation","image":"/assets/img/mediaeval-white.png","@type":"BlogPosting","headline":"Insight for Wellbeing","dateModified":"2020-07-09T21:03:05+00:00","datePublished":"2020-07-09T21:03:05+00:00","mainEntityOfPage":{"@type":"WebPage","@id":"/editions/2020/tasks/lifelogging/"},"url":"/editions/2020/tasks/lifelogging/","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

  <!-- Manual seo tags -->

</head>

  <body>

    <div>
    


<div class="navbar-fixed">
  <nav>
    <div class="nav-wrapper green darken-4">
      <a href="/" class="brand-logo" style="padding-left: 20px">
        <h3 class="northumbria" style="margin-top: 20px;color:white;">Mediaeval</h3>
      </a>
      <!-- Small screen definition -->
      <a href="#" data-target="mobile-nav" class="sidenav-trigger">
        <i class="material-icons" style="color:white;">menu</i>
      </a>
      <!-- Big screen Structure -->
      <ul class="materialize right hide-on-med-and-down">
        <li><a href="/"><i class="material-icons" style="color:white;">home</i></a></li>
        
          <li><a href="/editions/2020/" style="color:white;">MediaEval 2020</a></li>
        
        
          
            
              <li><a class="dropdown-trigger" data-target="editions" style="color:white;">
                MediaEval History<i class="material-icons right">arrow_drop_down</i>
              </a></li>
            
          
        
          
            
              <li><a href="/about/" style="color:white;">About MediaEval</a></li>
            
          
        
          
            
              <li><a href="/bib/" style="color:white;">Bibliography</a></li>
            
          
        
          
        
          
        
          
        
      </ul>
    </div>
  </nav>
</div>

<!-- Big screen dropdown Structure -->
<ul class="dropdown-content materialize" id="editions">
  
  <li><a href="http://www.multimediaeval.org/" target="_blank">pre-2020</a></li>
</ul>

<!-- Mobile Structure -->
<ul class="materialize sidenav green darken-4" id="mobile-nav">
  <li><a href="/" style="color:white;">Home</a></li>
  
  <li><a href="/editions/2020/" style="color:white;">MediaEval 2020</a></li>
  
  
    
      
  <li><a class="dropdown-trigger" data-target="mobile-editions" style="color:white;">
    MediaEval History<i class="material-icons right" style="color:white;">arrow_drop_down</i>
  </a></li>
      
    
  
    
      
  <li><a href="/about/" style="color:white;">About MediaEval</a></li>
      
    
  
    
      
  <li><a href="/bib/" style="color:white;">Bibliography</a></li>
      
    
  
    
  
    
  
    
  
</ul>

<!-- Mobile dropdown Structure -->
<ul class="dropdown-content materialize" id="mobile-editions">
  
  <li><a href="http://www.multimediaeval.org/" target="_blank">pre-2020</a></li>
</ul>

</div>

    

    <div class="container">
      <div class="row">
          <header id="main" style="background-image: url('')">
    <h2>Insight for Wellbeing</h2>
  </header>

  <!-- # please respect the structure below-->

<h4 id="task-description">Task Description</h4>
<p>Task participants create systems that derive insights from multimodal lifelog data that is important for health and wellbeing. The first dataset, namely “personal air quality data” (PAQID), includes air pollution data (PM2.5, O3, and NO2) and lifelog data (e.g., physiological data, tags, and images) collected by using sensors boxes, lifelog cameras, and smartphones along the predefined routes in a city. The second dataset, namely “global air quality data” (GAQID) includes weather and air pollution data collected over the city and provided by the government and crawled from related websites.</p>

<p>Participants in this task tackle two challenging subtasks:</p>
<ol>
  <li>Personal Air Quality Prediction with public/open data: Task participants predict the value of personal air pollution data (PM2.5, O3, and NO2) using only weather data (wind speed, wind-direction, temperature, humidity) and air pollution data (PM2.5, O3, and NO2) from public/open data sources (e.g., stations, website).  The target of this subtask is to investigate whether we can use public/open data to predict the personal air pollution data. The personal air pollution data can be concerned as the regional air pollution data since these data a locally collected by people who carry personal equipment. In other words, the ground truth is data collected by sensor boxes carried by people.</li>
  <li>Personal Air Quality Prediction with lifelog data: participants predict the personal Air Quality Index using images captured by people (plus GAQID). The purpose of this subtask is whether we can use only lifelog data (i.e., pictures of surrounding environment, annotations and comments), weather and air pollution data from open sources to predict the personal air pollution data.</li>
</ol>

<h4 id="motivation-and-background">Motivation and Background</h4>
<p>The association between people’s wellbeing and properties of the surrounding environment is an important area of investigation. Although these investigations have a long and rich history, they have focused on the general population. There is a surprising lack of research that investigates the impact of the environment at the scale of individual people. At personal scale, local information about air pollution (e.g. PM2.5, NO2, O3), weather (e.g. temperature, humidity), urban nature (e.g. greenness, liveliness, quietness), and personal behavior (e.g. psychophysiological data) play an important role. It is not always possible to gather plentiful amounts of such data. As the result, a key research question remains open: Can sparse or incomplete data can be used to gain insight into wellbeing? In other words, is there a hypothesis about the associations within the data so that wellbeing can be understood by using a limited amount data? Developing hypotheses about the associations within the heterogeneous data contributes towards building good multimodal models that make it possible to understand the impact of environment on wellbeing at the local and individual scale. Such models are necessary since not all cities are fully covered by standard air pollution and weather stations, and not all people experience the same reaction to the same environment situation. Moreover, images captured by the first-person view could give important cues to help understand that environmental situation in cases in which precise data from air pollution stations is lacking.</p>

<p>The key research question here is “does the personal air quality can be predicted by using other data which is easy to obtain?”.</p>

<h4 id="target-group">Target Group</h4>
<p>This task targets (but is not limited to) researchers in the areas of multimedia information retrieval, machine learning, AI, data science, event-based processing and analysis, multimodal multimedia content analysis, lifelog data analysis, urban computing, environmental science, and atmospheric science.</p>

<h4 id="data">Data</h4>

<h4 id="evaluation-methodology">Evaluation Methodology</h4>
<p>The ground truth for the dataset of the two subtasks is collected as follows:</p>
<ul>
  <li>For the Personal Air Quality Prediction with public/open data subtask: some parts of personal (PM2.5, O3, and NO2) data are deleted and saved as the ground truth.</li>
  <li>For the Personal Air Quality Prediction with lifelog data subtask: the set of personal AQI are hidden and saved as the ground truth</li>
</ul>

<p>For each subtask, the evaluation method is applied as follows:</p>
<ul>
  <li>For the Personal Air Quality Prediction with public/open data subtask: We use the SMAPE/RMSE/MAE for comparing each air pollution factor PM2.5, O3, and NO2 with the ground truth.</li>
  <li>For the Personal Air Quality Prediction with lifelog data subtask: We use the SMAPE/RMSE/MAE for comparing predicted AQI to the ground truth.</li>
</ul>

<p>The formulation for computing AQI value from (PM2.5, O3, and NO2) data can be found at 
https://en.wikipedia.org/wiki/Air_quality_index (Computing the AQI section)</p>

<p>http://taqm.epa.gov.tw/taqm/en/b0201.aspx (is the look-up table for C_low, C_high, I_low, I_high value)</p>

<h4 id="references-and-recommended-reading">References and recommended reading</h4>
<!-- # Please use the ACM format for references https://www.acm.org/publications/authors/reference-formatting (but no DOI needed)-->
<!-- # The paper title should be a hyperlink leading to the paper online-->
<p>[1] Sato, T., Dao, M.S., Kuribayashi, K., and Zettsu, K.: SEPHLA: Challenges and Opportunities within Environment – Personal Health Archives, MMM 2018. https://link.springer.com/chapter/10.1007/978-3-030-05710-7_27</p>

<p>[2] P. Zhao and K. Zettsu, “Decoder Transfer Learning for Predicting Personal Exposure to Air Pollution,” 2019 IEEE International Conference on Big Data (Big Data), Los Angeles, CA, USA, 2019, pp. 5620-5629. https://ieeexplore.ieee.org/document/9006604</p>

<p>[3] N. Nguyen, M. Dao and K. Zettsu, “Complex Event Analysis for Traffic Risk Prediction based on 3D-CNN with Multi-sources Urban Sensing Data,” 2019 IEEE International Conference on Big Data (Big Data), Los Angeles, CA, USA, 2019, pp. 1669-1674. https://ieeexplore.ieee.org/abstract/document/9005985</p>

<p>[4] P. Vo, T. Phan, M. Dao and K. Zettsu, “Association Model between Visual Feature and AQI Rank Using Lifelog Data,” 2019 IEEE International Conference on Big Data (Big Data), Los Angeles, CA, USA, 2019, pp. 4197-4200. https://ieeexplore.ieee.org/document/9005636</p>

<p>[5] Dao, M. S., Zhao, P., Sato, T., Zettsu, K., Dang-Nguyen D. T., Gurrin, C., Nguyen, N. T.: Overview of MediaEval 2019: Insights for Wellbeing TaskMultimodal Personal Health Lifelog Data Analysis, MediaEval Benchmarking Initiative for Multimedia Evaluation (MediaEval 2019), Antipolis, France (November 2019).</p>

<p>[6] Song, H., Lane, K. J., Kim, H., Kim, H., Byun, G., Le, M., Choi, Y., Park, C. R., &amp; Lee, J. T. (2019). Association between Urban Greenness and Depressive Symptoms: Evaluation of Greenness Using Various Indicators. International journal of environmental research and public health, 16(2), 173. https://pubmed.ncbi.nlm.nih.gov/30634488/</p>

<p>[7] Darshan Santani, Salvador Ruiz-Correa, and Daniel Gatica-Perez. 2018. Looking South: Learning Urban Perception in Developing Cities. Trans. Soc. Comput. 1, 3, Article 13 (December 2018), 23 pages. https://dl.acm.org/doi/10.1145/3224182</p>

<p>[8] Anh-Vu Mai-Nguyen, Trong-Dat Phan, Anh-Khoa Vo, Van-Luon Tran, Minh-Son Dao, and Koji Zettsu. 2020. BIDAL-HCMUS@LSC2020: An Interactive Multimodal Lifelog Retrieval with Query-to-Sample Attention-based Search Engine. In Proceedings of the Third Annual Workshop on Lifelog Search Challenge (LSC ’20). Association for Computing Machinery, New York, NY, USA, 43–49. https://dl.acm.org/doi/10.1145/3379172.3391722</p>

<h4 id="task-organizers">Task Organizers</h4>
<p>Minh-Son Dao (NICT, Japan) dao@nict.go.jp
Ngoc-Thanh Nguyen (UIT, Vietnam) thanhnn.13@grad.uit.edu.vn
Peijiang Zhao (NICT, Japan)
Duc-Tien Dang-Nguyen (UiB, NOrway)
Cathal Gurrin (DCU, Ireland)</p>

<h4 id="task-auxiliaries">Task Auxiliaries</h4>
<!-- # if there are people helping with the task, but are not bearing the main responsibility for the task, they are auxiliaries. Please delete this heading if you have no auxiliaries-->
<p>Tan-Loc Nguyen-Tai (UIT, Vietnam)
Dang-Hieu Nguyen (UIT, Vietnam)
Minh-Tam Nguyen (UIT, Vietnam)</p>

<h4 id="task-schedule">Task Schedule</h4>
<ul>
  <li>31 July: Data release <!-- # Replace XX with your date. Latest possible is 31 July--></li>
  <li>30 October: Runs due <!-- # Replace XX with your date. Latest possible is 31 October--></li>
  <li>15 November: Results returned  <!-- Fixed. Please do not change--></li>
  <li>30 November: Working notes paper  <!-- Fixed. Please do not change--></li>
  <li>Early December: MediaEval 2020 Workshop <!-- Fixed. Please do not change--></li>
</ul>

<p>Workshop will be held online. Exact dates to be announced.</p>


      </div>
    </div>

    
<footer class='page-footer green darken-4'>
  <div class='container'>

    <div class='row'>
      <div class="col l6 s12">
        <h5 class="white-text">What is MediaEval?</h5>
        <p>MediaEval is a benchmarking initiative dedicated to evaluating new algorithms for multimedia access and retrieval. 
          It emphasizes the ‘multi’ in multimedia and focuses on human and social aspects of multimedia tasks.</p>

        <p>For more information contact Martha Larson m.larson (at) cs.ru.nl</p>
      </div>
      <div class="col l4 offset-l2 s12">
        <h5 class="white-text">Links</h5>
        <a href='https://twitter.com/multimediaeval' target="_blank">
          <i class="fa fa-twitter fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
        <a href='https://github.com/multimediaeval' target="_blank">
          <i class="fa fa-github fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
        <a href='https://www.flickr.com/photos/69524595@N06/' target="_blank">
          <i class="fa fa-flickr fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
        <a href='https://www.youtube.com/channel/UCc-1NW1Uo2o_zI4F81iyTcw' target="_blank">
          <i class="fa fa-youtube fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
      </div>
    </div>

  </div>
    <div class="footer-copyright">
      <div class="container grey-text text-lighten-4">
      &copy; 2020 MediaEval Multimedia Benchmark
    </div>
  </div>
</footer>


    <!--JavaScript at end of body for optimized loading-->
    <script type="text/javascript" src="/assets/js/materialize.min.js"></script>
    <script type="text/javascript" src="/assets/js/main.js"></script>
  </body>

</html>
